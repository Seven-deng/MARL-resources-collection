# MARL resources collection
This is a collection of Multi-Agent Reinforcement Learning (MARL) Resources. The purpose of this repository is to give beginners a better understanding of MARL and accelerate the learning process. Note that some of the resources are written in Chinese and some papers that don't have a lot of citations wasn't listed. 

I will continually update this repository and I welcome suggestions.(missing important papers, missing important resources, invalid links, etc.) It's only a first draft so far, I'll add more resources in the next few months.

This repository is not for commercial purposes.

My email: chenhao2019@ia.ac.cn

## Overview


## Courses
* [RLChina 2020](https://rlchina.org/)
* [Multi-agent AI UCL](https://www.bilibili.com/video/BV1fz4y1S72S)

## Reviews
### Recent Reviews (Since 2019)
* A Survey and Critique of Multiagent Deep Reinforcement Learning
* An Overview of Multi-Agent Reinforcement Learning from Game Theoretical Perspective
* Multi-Agent Reinforcement Learning: A Selective Overview of Theories and Algorithms
* A Review of Cooperative Multi-Agent Deep Reinforcement Learning
* Dealing with Non-Stationarity in Multi-Agent Deep Reinforcement Learning
* A Survey of Learning in Multiagent Environments: Dealing with Non-Stationarity
* Deep Reinforcement Learning for Multi-Agent Systems: A Review of Challenges, Solutions and Applications
* A Survey on Transfer Learning for Multiagent Reinforcement Learning Systems

### Other Reviews (Before 2019)
* If multi-agent learning is the answer, what is the question?
* Multiagent learning is not the answer. It is the question
* Evolutionary Dynamics of Multi-Agent Learning: A Survey 
* (Worth reading although they're not recent reviews.)

## Books
* [Multiagent systems: Algorithmic, game-theoretic, and logical foundations](http://www.masfoundations.org/download.html)
* 

## Open Source Environments
* StarCraft Micromanagement Environment
   * [pymarl](https://github.com/oxwhirl/pymarl) This is the original environment mentioned in the paper [The StarCraft Multi-Agent Challenge](https://arxiv.org/abs/1902.04043). Note that pymarl is based on [SMAC](https://github.com/oxwhirl/smac).
   * [link](https://github.com/starry-sky6688/StarCraft) This is a simplified implementation of [pymarl](https://github.com/oxwhirl/pymarl)
* [Multi-Agent Particle Environment](https://github.com/openai/multiagent-particle-envs)
* [Neural MMO: A Massively Multiagent Game Environment for Training and Evaluating Intelligent Agents](https://github.com/openai/neural-mmo)
* [hanabi-learning-environment](https://github.com/deepmind/hanabi-learning-environment)
* [RoboCup 2D Half Field Offense](https://github.com/LARG/HFO)
* [Pommerman](https://www.pommerman.com/)
* [multi-agent-emergence-environments](https://github.com/openai/multi-agent-emergence-environments)
* [Google Research Football](https://github.com/google-research/football)
* [MAgent](https://github.com/PettingZoo-Team/MAgent) Note that [the original project](https://github.com/geek-ai/MAgent) is no longer maintained.
* (I personally recommend the first two environments for beginners.)

## Research Groups
Organization|Reaearcher|Lab homepage(if any)
--|:--:|--:
Oxford|Shimon Whiteson, Jakob N. Foerster|http://whirl.cs.ox.ac.uk/  


## Paper list
* 
* 
* 

## Useful Links
* 
* https://spinningup.openai.com/
* https://github.com/openai/spinningup
* http://www.neurondance.com/
* https://www.zhihu.com/question/376068768
* https://www.zhihu.com/question/323584412
* 
* 
* 
* 

## Other related stuff
* 
* 
* 

## TODO
* 
* 
* 




## 








