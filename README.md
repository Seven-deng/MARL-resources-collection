# MARL resources collection
This is a collection of Multi-Agent Reinforcement Learning (MARL) Resources. The purpose of this repository is to give beginners a better understanding of MARL and accelerate the learning process. Some of the resources are written in Chinese.

I will continually update this repository and I welcome suggestions.(missing important papers, missing important resources, invalid links, etc.) It's only a first draft so far, I'll add more resources in the next few months.

This repository is not for commercial purposes.

My email: chenhao2019@ia.ac.cn

## Overview


## Courses
* [RLChina 2020](https://rlchina.org/)
* [Multi-agent AI UCL](https://www.bilibili.com/video/BV1fz4y1S72S)
* 

## Reviews
###Recent Reviews(Since 2019)
* A Survey and Critique of Multiagent Deep Reinforcement Learning
* An Overview of Multi-Agent Reinforcement Learning from Game Theoretical Perspective
* Multi-Agent Reinforcement Learning: A Selective Overview of Theories and Algorithms
* A Review of Cooperative Multi-Agent Deep Reinforcement Learning
* Dealing with Non-Stationarity in Multi-Agent Deep Reinforcement Learning
* A Survey of Learning in Multiagent Environments: Dealing with Non-Stationarity
* Learning to Communicate in Multi-Agent Reinforcement Learning : A Review
* Algorithms in Multi-Agent Systems: A Holistic Perspective from Reinforcement Learning and Game Theory
* Deep Reinforcement Learning for Multi-Agent Systems: A Review of Challenges, Solutions and Applications
* 
* 
* 
* 


###Other Reviews(Before 2019)
* 
* 
* 
* 
* 
* 
* If multi-agent learning is the answer, what is the question?
* Multiagent learning is not the answer. It is the question
* 
* 
* 
* 
* 
* 
* (Worth reading although they're not recent reviews.)

## Useful Links
* 
* https://spinningup.openai.com/
* 
* http://www.neurondance.com/

## Books
* 
* [Multiagent systems: Algorithmic, game-theoretic, and logical foundations](http://www.masfoundations.org/download.html)
* 

## Open Source Environments
* StarCraft Micromanagement
   * [pymarl](https://github.com/oxwhirl/pymarl) This is the original environment mentioned in the paper [The StarCraft Multi-Agent Challenge](https://arxiv.org/abs/1902.04043). Note that pymarl is based on [SMAC](https://github.com/oxwhirl/smac).
   * [link](https://github.com/starry-sky6688/StarCraft) This is a simplified implementation of [pymarl](https://github.com/oxwhirl/pymarl)
* [Multi-Agent Particle Environment](https://github.com/openai/multiagent-particle-envs)
* [Neural MMO: A Massively Multiagent Game Environment for Training and Evaluating Intelligent Agents](https://github.com/openai/neural-mmo)
* [hanabi-learning-environment](https://github.com/deepmind/hanabi-learning-environment)
* [RoboCup 2D Half Field Offense](https://github.com/LARG/HFO)
* [Pommerman](https://www.pommerman.com/)
* [multi-agent-emergence-environments](https://github.com/openai/multi-agent-emergence-environments)
* [Google Research Football](https://github.com/google-research/football)
* [MAgent](https://github.com/PettingZoo-Team/MAgent) Note that [the original project](https://github.com/geek-ai/MAgent) is no longer maintained.
* (I personally recommend the first two environments for beginners.)

## Research Groups
* http://whirl.cs.ox.ac.uk/
* 
* 



## Paper list
* 
* 
* 

## Other related stuff
* 
* 
* 

## TODO
* 
* 
* 




## 








